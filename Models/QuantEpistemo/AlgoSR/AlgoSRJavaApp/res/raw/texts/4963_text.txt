An assessment of Quality of Life (QOL) has been a topic of growing concern on a global scale. Although the concern is said to have originated in the 1930s (Wish, 1986), in the American context the adverse effects of urbanization and environmental concerns have led researchers to sharpen their focus on urban QOL over the past several decades. A cursory look at the literature reveals that research of QOL is considered to be a multi-dimensional frontier both from the conceptual and methodological approaches of study, and the study of QOL, especially in urban settings, has continued to claim research interest across a number of disciplines ( see, for example, Leiske, 1990 ; Muoghalu, 1991 ; Cicerchia, 1996 ; Aureli and Baldazzi, 1998 ; Young1999). Although there is general consensus on the meaning of the term quality, implying a sense of satisfaction of the people within an environment in which they live (Wish, 1986), the specific set of attributes (indicators) and the measurement (methodologies) have drawn considerable criticism from many quarters (Wish, 1986 ; Bayless and Bayless, 1982 ; Jacob and Witts, 1994). Nonetheless, as evidenced in the literature, the research contributions have laid a sound conceptual foundation, and improved theoretical and empirical knowledge.
Given the concentration of a diversity of people and activities, and the complex interaction between them over space and time, it is a formidable task to establish a universally accepted research framework for accessing QOL. Since -- despite an intuitive understanding of the term -- the specific meaning of quality is expected to vary, it is further contended that the researchers must define the concept and design appropriate instrument(s) to measure aspects of QOL that are deemed essential in particular environmental contexts (Frick, 1982). The "measurement of the concept" is one of the issues, as the "concept can be seen as an instrument for policy making and for social planning" (Pacione, 1982). Underlying and critical to all of this is obtaining data of a sufficient quality to allow for determination of a result. All too often the assumptions and calculus of the technique employed in determining the QOL measure dictate the data that can be included or must be discarded as opposed to the purpose of the study. Hence, bias arises even before any analysis is performed.
This paper explores a valuable new version of Nonmetric Conceptual Clustering [NCC] (Fisher and Langley, 1986) technique, which is solved based on RIFFLE software (Matthews and Hearne, 1991 ; Matthews, 1995) for measuring QOL. This method is far more generous in accepting data that easily could prevent the use of or corrupt more traditional methods such as factor analysis or even the simpler linear additive techniques. NCC as a non-parametric clustering method can include all levels of data, and does not require any transformations of the data set. Missing data, as long as the number of cases remain reasonable in number, require no ad hoc assumptions or adjustments. The solution is simply generated without addressing the missing points. The reason that these points have minimal effect on the results is that NCC maximizes predictive fit of the model not probabilistic. Hence, the purpose of the study drives the analysis not the data set.
As the first attempt to utilize NCC in evaluating QOL, this study will utilize an applied comparative manner. The QOL index of a small U.S. metropolitan area utilizing both NCC and factor analysis will be calculated and then described comparing the pros and cons of each technique. This implies that NCC is not a wholesale replacement for previous QOL measurement methodologies, but rather an alternative tool to be selected when appropriate to the needs of a given study, and far more independent of data constraints.
The remainder of this paper is organized in the following fashion. The next section discusses the general approach of cluster analysis and the methodologies used in previous QOL studies. This is followed by a description and discussion of NCC, which is followed with an applied analysis of QOL of a small metropolitan city comparing NCC results with traditional Factor Analysis, and then investigating a combination of these two techniques. Conclusions and suggested areas for further investigation close the paper.
Clustering is an organizational methodology dating back to the Ancient Greeks including Aristotle for investigating and understanding the essence of subgroups of the population. The procedure results in the formation of homogenous subgroups based on common properties of either the entities investigated or their accompanying attributes. Lorr (1983) defines the aim of clustering as falling into a number of categories which can be summarized under the general rubric of descriptive, hypothesis development and testing, and predictive. To this can be added a further level of refinement, the prescriptive. The descriptive has been used to identify existing natural or special purpose subgroups within a population. By studying these, new hypotheses can either be created or existing ones tested. Over time, as understanding of the process leading to a pattern grows, both prediction and finally prescription become possible.
Application of clustering analysis follows a number of well-defined steps :
Problem definition
Data collection and standardization/transformation
Dimensionality analysis
Selection of clustering method
Computation and geometric and geographic mapping
Comparison with alternate techniques and data sets
Of these steps several require further description. Depending upon the dimensionality and clustering technique selected, it may be necessary to standardize data sets (normalization or ordinalization being most common) and perhaps transform the distribution to meet assumptions of the technique (such as transformation into a normal curve). Dimensionality analysis (such as Principal Components or Factor Analysis) is recommended when the number of attributes is large. A smaller number of composite components can lead to a more concise and clear understanding of the underlying pattern. Clustering method selection should be based on expectation of cluster shape (compact or extended), dynamics (evolutionary -- hierarchical, or static -- single-level), index measure of similarity (geometric -- metric, or categorical -- non-metric), and solution search procedure (single linkage, complete linkage, average linkage, iterative partitioning, divisive...). Emphasis should be placed on the fact that the results should be mapped both in attribute or entity space (geometric) and geographic space. It is only through this latter mapping that it is possible to search for spatial components of statistical clusters. Finally, all results are best understood by searching for multiple confirmations of natural patterns by utilizing additional clustering methodologies and data sets.
QOL studies began as merely descriptive exercises, although more recent ones have now extended the work to the prescriptive or policy level. Given the subjective nature of QOL and reliance on secondary data sources, standardization of attributes utilized in such studies is unlikely. As a result the use of large and diverse data sets will remain the rule for the foreseeable future. Normalization and Transformation techniques are now readily available in statistical software packages, and should become a routine step in the future, although they have not been so in the past. Likewise, more flexible software makes the full utilization of dimensionality analysis more available before the selection of clustering technique. Many of the earliest QOL studies, utilized simple methods of ordinal index creation through summing normalized data, and then subdividing the results into quantiles. Such approaches gave a general, though crude, view of QOL variation over space. Questions of which variables to include, units of measurement, level of measurement (ordinal or interval), and weights to apply remained problematic.
Later studies favored principal component methods and factor analysis. Limitations to these studies include the fact that data do not always meet the required assumptions of the technique, missing data are not handled well, and all variables remain in the analysis, even noisy ones with weak correlation and large variance that may bias the resulting clusters. Further studies utilizing these approaches rarely included any additional clustering technique. Entity factor scores in R mode analysis, or entity factor loadings in Q mode analysis were generally mapped across space for each component and conclusions drawn. Few attempts were made to combine components into more general clusters.
Finally, given the past difficulties of calculation and parsimonious nature of the data, few if any attempts were made to apply additional clustering methods or to draw additional samples to verify results.
Nonmetric conceptual clustering is a form of nominal scaling, based on iterative partitioning of the data entities into groups or clusters based on attributes. This enables us to overcome many of the shortcomings of previous methods for investigating QOL and to provide an additional means of investigating the data for structure and pattern. As a result, NCC does not replace earlier methods, but instead extends and enhances them by providing an additional means of investigating the data either with or without dimensionality analysis.
Advantages of NCC include :
As a nonparametric measure it can utilize all levels of data without transformation (although as will be detailed later, there are some limitations in Q mode analysis).
No ad hoc assumptions are required to handle data which is missing, below detection, or suppressed ; either an additional attribute category can be created to handle such cases or entities with such attributes are eliminated from only that portion of the analysis focusing on the problem attribute.
It is able to detect and control for noisy variables, those with weak correlation to other attributes and high variance.
It utilizes a "Nonmetric fitness" quality measure (NMF), generated by averaging the Proportional Reduction in Error (pre), which is based on a variation of Guttman's lambda (Matthews, 1995 ; Goodman and Kruskal, 1954 ; Guttman, 1941). NMF determines optimal fit between the data and the cluster model. The result is a model that maximizes predictability, not probability. A detailed description of this measure is provided below.
Determination of optimal clusters based on NCC is performed here using RIFFLE software (Matthews and Hearne, 1991 ; Matthews, 1995). RIFFLE experiments with arranging entities (in our case neighborhoods) into distinct clusters that maximize predictability of attribute values that describe members of a cluster. Thus, by knowing cluster membership for a neighborhood, we can predict attribute values describing it.
To provide a clear understanding of the RIFFLE solution procedure we have divided the explanation into two parts, even though they interact in a simultaneous fashion. First, we describe how the pre and the summary NMF measures are generated and applied. Second, we describe the steps performed by RIFFLE to discover a cluster pattern that maximizes these measures of predictability. However, before providing a step by step explanation of pre and NMF it is necessary to understand that to perform NCC analysis all continuous attribute data must be transformed into categories. More detail will be provided on this procedure in the next two sections.
The measures of predictability, pre and NMF are calculated and applied in the following fashion :
Drawing on any prior knowledge, such as sample design, determine the Ignorance Error (IgnE) that exists if one was to predict the categorical attribute value for a randomly selected entity. For example if a sample was created of an equal number of males and females, there would be a 50% chance of making an error in guessing the gender of an individual randomly selected from the full data set. This a priori level of knowledge or lack of knowledge is defined as the ignorance error.
After using NCC to sort the entities into clusters expected to optimize attribute similarity among group members, error can again be calculated. This is Informed Error (InfE) of predicting an attribute value if the cluster membership is known. For example for the same sample as created above, assume that income has also been collected. Next individuals could be sorted into two clusters, Group A with high incomes and B with low. Since males tend to have higher incomes Group A would have an over-representation of this gender. Knowing that an individual belonged to Group A would enable us to predict that an individual's gender is male and be wrong less than half of the time. Let us say that 90% of the members of Group A are males, and the remaining 10% are female. Thus, our error in guessing gender knowing membership in Group A or Group B would drop from 50% to 20% ; that is we would be wrong 10% of the time when guessing male for Group A and a similar 10% when guessing female for Group B. The total error when informed of the cluster to which an entity belongs would be 20%. This latter value is the measure of InfE.
By combining these two measures the Proportional Reduction in Error (pre) for predicting the attribute value based on knowledge of cluster assignment is determined from the following equation : pre = [(IngE - InfE)/ IngE)] In our example this is  : pre = [(.50 - .20)/ .50)] = .60 or error has been reduced by 60%. pre ranges from 1.0, where all error has been eliminated and perfect predictability exists, to 0.0, where no reduction in error occurred from cluster assignment.
NMF is a measure of over-all cluster fit and is determined by averaging pre across all attributes included in the model.

Table 1 : sample data set

Table 2 : two cluster mean partition based on average house value

Table 3 : two cluster median partiton based on average house value
A short example follows to illustrate these principals. Given ten neighborhoods described by three variables, two nominal and one interval (see Table 1), a two-cluster solution is developed. Table 2 demonstrates results from possible partitions of the continuous House Value variable into categories based on a mean split, while Table 3 is based on a median partition. Finally, both tables illustrates the pre for each of the three attributes and the over-all average or NMF when neighborhoods are sorted into clusters of high and low value residencies.
Based on the mean partition, pre for the value attribute is 100%, as should be expected after sorting the neighborhoods by value. View has a 50% pre, but Freeway has no discernable improvement. Across the three variables, the NMF is 50%, meaning the error of successfully predicting attributes attached to neighborhoods decreases by 50% on average if we know the cluster to which a neighborhood has been assigned.
However, predictability further improves to an NMF measure of 67% if median is used as the partition point for the value attribute despite the fact that pre does not improve. This also illustrates how outliers that heavily weight metric clustering measures can be controlled for in NCC.

Table 4 NMF FOR ALTERNATE CLUSTERS
Table 4 experiments with additional easily understood cluster combinations. All cases here reinforce the use of the median partition rule over the mean for the data set at hand. Further, it shows that for the sample case the value attribute happens to provide the best organizer of neighborhoods into clusters. However, it should be noted that RIFFLE, unlike this example, does not sort data based on the a single attribute, but rather searches for the cluster assignment that produces the optimal NMF. Just as it should be noted that more than one cluster combination has an NMF of 0.50, additional cluster combinations and partition rules might exist that equal or exceed the optimal 0.67 NMF presented above. Only after neighborhoods are assigned to all possible combinations under all possible partitions of continuous variables, can a global optimal solution be assured. In the small example here, it would be possible, though tedious, to explore all possible solutions, but the same would not be true of larger or more complex data sets.
It should also be apparent ; even though not demonstrated in the above example, that small numbers of missing or suppressed datum values would not radically alter the outcome of this analysis. Those values that do not exist (for example a neighborhood with unreported average house value) simply are not included in calculating the pre measure for an attribute.
One problematic issue with NCC based on NMF is that simple models may have greater predictive power than more complex ones. This raises the issue of how many clusters and how many variables should be included in a model. With nominal data the maximum number of clusters is controlled by the maximum number of categories in the attributes, with continuous data only the number of neighborhoods limits the number of possible clusters. In reference to the variables, for a fixed number of clusters, based on NMF once the best variable(s) has been chosen (i.e. those with the highest pre), additional variables will cause this measure to decrease. Hence, it is important for the researcher to have a strong theoretical grounding in the phenomena being investigated and let theory assist in dictating model complexity, but this has always been the case with QOL studies.
A second issue, especially relevant to geographers, is spatial display of the results. Again, from the example it is apparent that some neighborhood assignments to clusters contain inconsistencies in some but not all of the attributes. It would be possible to display this variation in fit by assigning shades of the same color to a single cluster's neighborhoods indicating how well a given member fit the over-all cluster. However, investigation of spatial autocorrelation across the study area could prove to be troublesome.
The RIFFLE solution algorithm is a series of nested-search routines that determine optimal measures of pre and NMF based on the number of clusters and attributes included in the model. Four nested-searches are possible. Starting from the innermost they are : (1) partitioning of continuous attributes into categories to maximize pre for individual attributes, (2) selecting the best set of attributes based on NMF, (3) selecting the best assignment of entities to clusters also based on NMF, and (4) selecting the correct number of clusters. RIFFLE automates the first three search routines, and the researcher can investigate the outer most by exogenously indicating the range of the number of clusters to model.
The solution procedure begins in attribute space with the partitioning of continuous attributes into quantiles based on rank order to reflect the number of clusters desired. In entity space it simultaneously randomly assigns all entities to a cluster. Then using a "hill climbing routine" RIFFLE adjusts the attribute partition to maximize pre for each attribute in the data set. Next, using NMF it searches for the optimal combination of attributes that can be predicted based on the number of attributes desired in the model. Finally, with a second "hill climbing routine", RIFFLE experiments with moving entities between clusters to see if NMF can be further improved. Every time an entity is moved between clusters, RIFFLE returns to the innermost search routine and works outward. A solution to the process is the cluster assignments of entities that provides the greatest over-all predictability of attribute categorical values for a given number of attributes. Since "hill climbing routines" only guarantee local maximums not global optimums, upon completion of a solution, RIFFLE re-seeds the initial random assignment of entities to clusters and repeats the above steps. Matthews and Hearne (1991, 179) report that, "the number of repetitions necessary is, of course domain dependent, but in practice we have never found more that about 50 to be necessary."

Table 5 Attribute Names and Definitions
The present research is focused on Bellingham, a city of 50,000 in the state of Washington with significant growth management issues. Two sets of indices, physical and social (Table 5), are employed across 22 neighborhoods of the city. Data for each neighborhood were collected and compiled from the census reports and various city and community data sources.
As noted earlier, factor analysis is a very widespread method for identifying composite measures of QOL. To apply it in this study, it became necessary to ordinalize the data. Several of the original attributes were highly skewed, especially a measure like Acres of Parkland due to unequal size and distribution of parks. Further, as noted earlier, nominal data is not handled well in factor analysis. In addition, even if the data had been normally distributed, to perform Q mode analysis transformation to a common metric would be necessary.
To the authors' knowledge this is the first time that NCC has been applied to a QOL study. For the R mode analysis discussed here, no transformation was required. However, to also include Q mode, a common metric across the attributes would be required (z scores being an obvious choice) and nominal data could not be included, limitations similar to those for factor analysis. However, no such changes or limitations are required for R mode analysis.

Table 6 Factor Analysis R Mode Results
From the factor analysis R mode results (Table 6), 6 factors explain 82.6% of the variation. Of these only the first factor combines both physical and social attributes. This factor describes neighborhoods with more motivated individuals (note high education attainment), low crime, low traffic due to few arterials, access to parks, and few multiple unit dwellings. Basically the fulfillment of the "American Dream", and what many might expect to be the only mode of living in a small American city. Factor two clearly defines high and low income areas. The third factor describes ex-urban areas, with remaining undeveloped open space. Factor four provides a second measure of income, but focuses more on affordability of housing and the related social structure. The fifth factor simply demonstrates that incompatible uses have been successfully zoned apart. Finally, factor six demonstrates that traffic flow is related to the total amount of roads ; not a particularly enlightening finding.
Of the components only the first appears to get to the heart of QOL measures, the remaining highlight economic segregation, ex-urban neighborhoods, zoning, and road-traffic correlation. Basically, after the first factor social and physical attributes show little connection.

Table 7 Geary and Moran Spatial Autocorrelation for R Mode Factor Scores
* significant at the 10% level
Spatial autocorrelation of the factor scores are provided in Table 7. Only the first factor demonstrates clustering at an alpha of 10%. Mapping this factor (Map 1) revealed a strong northwest-southeast pattern of clustering, with negative scores concentrated in the northwest and positive values in the southeast.

Map1 : American dream factor

Table 8 RIFFLE Generated NMF Quality Measure Summary of Results Based on Attribute Data for all 22 Neighborhoods

Table 9 Inclusion of Attributes in 2-Cluster Runs, pre values in matrix and NMF at bottom

Table 10 Inclusion of Attributes in 3-Cluster Runs, pre values in matrix and NMF at bottom

Table 11 Inclusion of Attributes in 4-Cluster Runs, pre values in matrix and NMF at bottom
Table 8 provides a summary of the NMF measures from RIFFLE for R Mode analysis based upon the number of attributes and clusters included in the analysis. For the data set at hand it is apparent that the more complex the model (increased attributes and clusters) the lower the predictability (i.e. NMF declines). Thus, increasing the complexity of the model, departs from the full predictability of the simplest case ; the 2-cluster, 2-attribute model which provides perfect prediction of a neighborhoods educational attribute values given cluster membership.
A second major point is that as the number of attributes and clusters are increased there is some instability as to which attributes remain in the analysis. Tables 9 through 11 detail the optimal variables included in each run, their pre and NMF values, and how many times they appear in the models. Finally, it should be noted that the tables above concentrate on attribute and entity space. Later these results will be translated into geographic space for a few key combinations of clusters and attributes. Also, as noted previously, the exact number of variables and clusters that should be introduced is not certain, much as the in the case of factor analysis. However, unlike factor analysis, here it is possible to explore a model as it increases in complexity.
In reviewing Tables 9 through 11 it is apparent that two separate focuses occur in this data set, an education focus (linked to the "American Dream" factor in Table 6) and an economic focus (related to the first "Economic" factor). Note in Table 9 for 2-clusters as up to 4 attributes are added to the model, BA% and HS% dominates. For 5 and 6 attributes, economic factors clearly dominate the results. Then for 7 and more attributes some combination of these two focuses are clearly in the model. Looking further at the 3-cluster model (Table 10), the economic attributes dominate until again a combination of the education and economic attributes enter the model for the 9 and 10 attribute level. Finally, the 4-cluster model moves quickly from the education dominated 2-attribute model to an economic dominated model until at least 8 attributes are included. To fully understand why this apparent instability occurs in the analysis, it will be necessary to move into geographic space, but first a bit more focus in attribute and entity space will be helpful.

Table 12 Variable Entry : Two-Cluster Results, Highest NMF and Closest Alternate
Two-Cluster : In attempting to clarify the patterns emerging from the data, analysis was focused on 6 or fewer attributes for 2-cluster through 4-cluster results. Besides limiting the analysis to robust models (even the most complex 4-cluster 6-attribute model has a MNF of 70%), this also allows for some direct comparison between models based on the education lead attributes and economic ones. Table 12 focuses on the 2-cluster results. Note how education, BA% and HS%, dominate the 2- and 3-attribute models. However, at the 4-attribute level, NMF is basically equal for the education based model and an economic based one. By the time that 6 attributes have been entered, the slightly weaker alternate education based model (labeled 6 alt.) has 5 of the 6 attributes identified in Table 6 for the "American Dream" factor. Only RsMult% is missing, being replaced by Ethnic%. Likewise the 6-attribute model based on economic factors (labeled 6) also has 5 of the 6 attributes included in the second factor from Table 6. Thus, it is apparent that NCC is also identifying the strongest two factors from Table 6.

Table 13 Variable Entry : Three-Cluster Results, Highest NMF
Three-Cluster : These results are quite stable over entry of the first six attributes, but loose a little predictive power in comparison to the two cluster case above. Second, the variables captured here more clearly match the economic factor (factor 2) with a match of five out of the six attributes. The sixth variable, FemHH%, is captured in the second economic factor (factor 4). Again, strong confirmation of results from the two methodologies is being provided. The new information provided here seems to be that the purely income based division of the city is better modeled with more than two clusters.

Table 14 Variable Entry : Four-Cluster Results, Highest NMF
Four-Cluster : Since four is an exact multiple of two, it is not unusual for a four-cluster result to be highly similar to the earlier two-cluster result. Here that result is seen with BA% and HS% chosen for the two variable case. However, for more than 2 attributes the results are basically the same as the three-cluster case, but with no better predictive power. For the six variable case, RsSing% replaces the PovrtFm%, not a surprising result, all others are the same.

Map 2 : 2 Cluster, 5 Variable Education Focus

Map 3 : 2 Cluster, 5 Variable Economic Focus

 Map 4 : 3 Cluster, 3 Variable Economic Focus

Map 5 : 4 Cluster, 2 Variable Education Focus
Geographic Space : To fully understand the variation in models based on attributes and clusters it is necessary to introduce geographic space. Cluster assignments are made in NCC to maximize predictability based only on entity space. By spatially mapping the clusters that result, a more complete understanding of the underlying processes is possible. Maps 2 through 5 provide some insight in this area.
Maps 2 and 3 show the clear spatial difference of the education and economic based models based on a 2-cluster, 5-attribute approach. With education attributes as the guiding principles in Map 2 (entry 5 alt. In table 12), the city is very definitively divided north and south, confirming the results found in Map 1 for the factor analysis. Map 3, based on the economic attributes (entry 5 in Table 12) demonstrates more of a core/periphery condition. Much as would be expected in any older American metropolitan area, the inner parts of the city have lower levels of QOL than the outer more suburban areas.
Turning to more complex 3-cluster, 3-attribute model that focuses on economic attributes (Map 4), the core area remains well defined, but the periphery proves to be a bit more complex. More analysis would be required here before a complete explanation could be attempted. Finally, just to show how greater complexity can quickly result from additional clusters, a rather simple 4-cluster, 2-attribute diagram is provided (Map 5).
Conclusions : Two major results can be drawn ; (1) the two major factors identified in the factor analysis are also confirmed in the NCC analysis, and (2) full explanation involves exploration of geographic space as well as attribute and entity space.
The two methods compliment one another. Both capture an education and economic component as the most important organizing principles in the data. Factor Analysis' advantage is that it also identifies additional components from the data. However, this is also its weakness of having to include all the data somewhere. NCC, on the other hand, provides for a greater understanding of how increased complexity (more variables and clusters) in the model effects the results. It is a better method for building or dissecting a result.
For spatial display and analysis of the data, factor analysis is a familiar, well-documented technique. Based on the factor scores, neighborhood contributions are easily graphed on a map of the city and spatial autocorrelation can be investigated using traditional statistical tools. NCC also lends itself to analysis in geographic space, and as demonstrated here it provides important clues to more fully understand processes underlying patterns. A shortcoming of NCC is that neighborhoods are exclusively assigned to a cluster even if the predictive fit is not perfect. Further, no measure is currently available to indicate how well a given entity fits into a cluster. This certainly is an area open for more research. Finally, given the categorical nature of cluster assignments in NCC, more than nominal spatial autocorrelation analysis may prove to be problematic.
The main conclusions drawn from this study can be grouped into two major areas : impacts on QOL studies, and comparison of the two techniques.
The major benefit of this study is to provide an investigation into a method with improves the objectivity of QOL measures. Given the nominal scaling approach of NCC, all levels of data are accommodated and without prior transformation in the R-Mode approach. In addition, although not illustrated here, missing data requires no ad-hoc adjustments. Finally, highly noisy data with large variance has no special impact on the results. Thus, the inclusion of acres of parkland in a neighborhood, where one or two neighborhoods may have extremely large parks and the remaining neighborhoods small ones requires no special data standardization or transformation.
In the comparative study, the most important conclusion is that of the similarity in the outcome of the strongest results. The advantage of NCC, however, is its ability to build this result in a step by step fashion while indicating the level of explanatory power the model had as it evolved. Secondly, NCC indicated how greater complexity decreases predictive power. Further, unlike factor analysis, there are no underlying orthogonal components in the NCC. Hence, what you get is what you see. Based on the actual untransformed and/or unrotated variables a model is built and its predictive power demonstrated. This can be very helpful in building a model in a stepwise fashion, as opposed to factor analysis' complete entry of all variables in the data set. Finally, both techniques lend themselves to analysis in geographic space, which again provides additional explanatory power. Add to this NCC's ability to build a model in a step-wise fashion, and the end result is much more informative.
Both of these methods should be included in the researcher's toolbox. Depending on the data available and theories being investigated, each technique will provide valuable insights. In sum, a number of highly useful results came from this study but additional work should be continued. Especially further attempts to fully utilize NCC's output in geographic space.
