The second half of the nineteenth century saw a growth in the number of international scientific congresses1. A frequent topic of discussion in these gatherings was the definition of "common means of measurement, notation and expression", an objective inspired by the principle of universalism of science. The need for improved communication was widely felt, and many debates were concerned with language in a broad sense, with the aim of reducing the "babelisation" or confusion that resulted from disparate national practices.
Projects for unification involved terminologies, as well as codes or sign systems, including graphical expression by means of diagrams and maps. It was not long before these began to be described using the language metaphor. Graphical signs were assimilated to a discourse that could be read, understood and criticized on grounds of efficiency, and not simply for reasons of personal preference or style.
Visual language had been used by statistics since the end of the eighteenth century. Up to the middle of the nineteenth century, however, graphical expression tended to be considered as straightforward and unscientific2. But the use by statisticians of graphical methods, and particularly maps, increased after 1850. The French engineer Charles-Joseph Minard observed in 1861 that "there [was] a general impulse of people´s minds towards graphical representations"3.
This development was visible in official publications and on the occasion of universal exhibitions. But abundance was also a source of "confusion of language", and in the second half of the nineteenth century many statisticians began calling for the establishment of a grammar or a syntax. The international congresses of statistics served as the forum for a debate, mainly between Europeans, about the standardization of graphical methods. This debate continued in the International Institute of Statistics until the beginning of the twentieth century. But the exchanges of views failed to produce concrete decisions.
We begin by presenting the content of the debate, then try to explain the reasons for failure. In addition to a questionable project of standardization and the diversity of national practices, the main difficulty seems to have been theoretical : standardization4 was defined too narrowly, as the choice of specific signs or methods. The project should have concerned the choice of general rules and principles.
The advantages of visualization in statistics were stressed by many authors in the course of the nineteenth century. William Playfair wrote in 1802 that "regarding numbers and proportions, the best way to catch the imagination is to speak to the eyes"5. This idea was later endorsed by Alexander von Humboldt, followed by Quételet and Dupin. Around the middle of the century, the idea was reinforced by the cartographic works of the civil engineers, such as Belpaire and Minard6. At the same time, authors developed the linguistic metaphor : graphical representations were elements of a language, one that used the "active and powerful sense" of sight. Statisticians were initially confident about the effectiveness of the image as compared with numerical tables. The former spoke to the eye without straining the mind.
From the 1870s, however, opinions became more qualified, even though the advantages of images continued to be emphasized. The growing number of applications and differing interpretations of statistical series was accompanied by a critical examination of the methods, their qualities and effectiveness. The project for a codification of graphical language resulted from the new profusion of representations. We can quote the view expressed by Emile Cheysson, French engineer, in 1878, on the occasion of the Universal Exhibition in Paris. Cheysson observed the confusion that existed among scientists using the graphical method. The absence of rules might have stimulated creation and imagination, but this could not go on any longer. "The time will come", wrote Cheysson "when Science has to lay down general principles and decide on well-defined standards. We can no longer tolerate this sort of anarchy"7.Cheysson strongly urged preparation of a code, even if only in a provisional form, or at least to make a start on the work. The first task could be a classification of graphical methods and the definition of standards.
The debate over the code was carried on in statistical journals and societies, but the main occasion for discussion of the subject was at international conferences, for the confusion of languages was an international rather than a national problem.
Classifications were the first point to be studied by statisticians.
Cheysson´s views had in fact been stated several years after the first attempt at a classification, at the third session of the international congress, held in Vienna (Austria) in 1857. That attempt had taken the form of a "synoptic table", classifying methods by subject matter, i.e. four categories of human knowledge. Concrete examples of graphical methods were given for each category.
This classification was premature and had many defects : the inventory of methods was incomplete, and the principle of the table was incorrect, for a graphical method could not be considered as the expression of a single category of knowledge. It was criticised on several counts. The table was inadequate and the shortcomings of its vocabulary were striking. Dr Ernest Engel, director of the Prussian statistical office, was ironical about the non-scientific terminology : "I wish to draw the attention of this worthy company to the fact that the expression : ´set of lines taking the shape of Pan pipes´ has nothing to do with science" (the authors of the table meant "histograms")8.The reservations of many participants resulted in the Vienna classification being in effect abandoned. The problem of classifying methods was not taken up again until the 1870s, at the approach of the St Petersburg congress. At that time, the Bavarian statistician Gustav von Mayr stimulated debate with a report on the graphical method, entitled Gutachten über die Anwendung der graphischen und geographischen Methode in der Statistik, published in 1874. Mayr made the distinction between maps and diagrams, and then he defined the subdivisions of each class. Other approaches were in fact possible, such as a division of figures according to the number of observations or number of variables. Yet most statisticians departed little from Mayr´s theory. Later authors like Cheysson and Levasseur also favoured classifications based on form rather than content.
There was no true debate on the subject of naming and classifying. Statisticians were concerned mainly with the question of standardization. This question was in two parts. First, there was discussion of the principle itself : would it be worthwhile and effective to standardize visual representations ? Second, there was the issue of the detail of graphic rules and design standards.
In 1857, at the time of the Vienna congress, the sixth section left to individual authors the choice of symbols. The question of graphic rules was tackled at the congress in The Hague in 1869. Obreen, director of the Map Division of the Dutch Ministry of Navy, presented a report about the graphic method in the first section of the congress. This report and the discussion which followed showed that many participants did expect an attempt to be made to establish graphic laws.
Obreen did not advocate a universal system of signs. He merely gave advice and recommendations about graphic constructions, but appeared content to wait for the next congress, where the graphical method was to receive a thorough examination. Such caution was justified, since the discussion about methods at the meeting on 8 September revealed extensive differences of opinion. Nevertheless, Dr Ernest Engel used the example of standardization of geological maps to argue that "it was of the utmost importance that statisticians should achieve uniformity"9. He recommended preparation of another report on methods, accompanied by proposals for their unification.
The conclusions on this question were set out at the end of the congress, on 11 September, by a Belgian statistician, Dr Janssens, responsible for the first section. He announced that any decision about the adoption of rules for graphic constructions was suspended, and postponed it until the next congress.
The Hague congress decided to put off making a decision10. A resolution was passed, however, in accordance with Engel´s wish, for the preparation of another report. Three reports were in fact presented at the congress of St Petersburg, in 1872. Two of these concerned the problem of unification 11Anwendung der Kartographie auf Zwecke der Statistik, written by Adolf Ficker, director of the statistical administration of Vienna, focused on maps, and Theorie der graphischen Darstellungen, by H. Schwabe, from the statistical bureau of Berlin, mainly on diagrams.
The rules discussed at St Petersburg will be examined later, but first let us look at the principle of standardization itself. Schwabe and Ficker´s papers were discussed in the first section "Methodology of statistics". Through Schwabe and the French statistician Emile Levasseur, the section then put several resolutions to the vote of the entire congress. The first stated : "The Congress accepts that it is not worth going into details about the choice of methods or facts for graphical representation". The third specified that "concerning uniformity, the Congress declares, contrary to the resolution of The Hague, that no strict rule can be imposed on authors, because the only real problem is that of applying the graphical method to data that is comparable".
These and other resolutions produced a lively discussion in the general meeting of the congress. Several members still demanded comparability not only of data but also of methods, and even of scales and dimensions. Schwabe defended the resolutions of the first section. He likened the problem to "trying to square the circle". The different methods in use were too individual, too specific, irreducible. "How could we unify all these children of whim and mind, whose shapes are so particular and so outstandingly different ?"12.
The Berlin statistician argued that unification not only had disadvantages, such as limitations of format, but would be a mistake : for Schwabe held that the value of a representation lies in its individuality, which must not be sacrified. Speaking about cartograms (at that time the term meant statistical maps), Levasseur agreed with Schwabe, and recommended allowing authors to act with complete freedom and not to stifle creativity : "your first section believed its role was to encourage and promote graphical methods. It would be acting contrary to this aim to confine artists within too rigid rules"13.
Taking all things into consideration, including the views of statisticians like Engel, the congress voted for a compromise : the text "no uniform rule can be imposed" became : "the time has not yet come to propose uniform rules"14. Although this position appeared to prepare for future change, the topic was in fact never again examined.
The question of standardization was considered by the standing committee, at its meeting in Stockholm in 1874. This committee had to draw up the programme for the next congress, but it took the view that the resolutions about graphical methods were too recent for changes to be considered, and so the question was dismissed. At the standing committee´s fourth session, held in Paris in 1878, a new member, the French engineer Emile Cheysson, returned to the subject. Pointing to the progress of statistical maps since the last congress, he called for the elaboration of a code. Dr Engel objected that the question had been examined at Vienna and St Petersburg, and reminded him of the resolutions of 1872. However, Cheysson was put in charge of preparing another report on graphical statistics.
From report to proposal, the discussion lasted until the end of the century. Although both Cheysson and Vauthier talked of standardization, there was no agreement among French statisticians either : thus Emile Levasseur continued to reject graphical rules, a position he reaffirmed at the jubilee of the Statistical Society of London, in 1885.
At the end of the century, there was no further attempt to return to the question. The last statistical congress was held at Budapest in 1876, whereupon an International Institute of Statistics took over, with sessions every other year. Within the institute, we can note a final attempt by French statisticians to relaunch the project, in 1901. Dr Jacques Bertillon (son of Louis-Adolphe) presented his Propositions about the uniformity to be achieved in graphical constructions15. The text was prepared in collaboration with Cheysson (from the Ministry of civil engineering) and Fontaine (Ministry of Trade). According to them, it was necessary to eliminate "inconsistencies of spelling" and perhaps establish a few basic conventions. But the debate had not advanced, and these proposals were not even put to the vote.
These results can be compared with those obtained by other scientists in their international congresses. A case in point is the discussion among geologists over the standardization of symbols for geological maps. The debate occurred at the same period : there was a first project in 1878, then several resolutions were adopted at the congress of Bologna in 1881.
So why did the statisticians fail in the same project ? The main reason for the rejection of the principle was the lack of agreement over choropleth maps. This method, first developed in 1826, was certainly the most commonly used in the second half of the century, but it took various forms. The statisticians were faced with two problems : how to divide a statistical series, and how to shade the map ?
These points were raised at Vienna in 1857. The Austrian V. Streffleur and the German P. Sick proposed a maximum of three colours and twelve class intervals. But this arbitrary choice was rejected by the great majority, and calculation was not even adopted as the method for forming class intervals.
The discussion continued at the congress of The Hague. Should the statisticians select a single method for forming the intervals, and, if so, which ?
There were two opposing positions. The first was supported by Ficker, who advocated a "natural" mode : this involved selecting as interval limits the largest gaps between the numbers. The second position, defended by von Mayr, was a mathematical mode : to substract the minimum from the maximum and form the groups by dividing the result into equal parts.
French statisticians chose between these two modes, with slight variations. For example, Toussaint Loua followed Ficker, trying to identify breaks in the statistical series, for his Atlas statistique de la population de Paris. Louis Bertillon, for his medical maps, evoked von Mayr´s ideas, which in fact derived from Quételet (the "module de précision" of statistical series), and the quantile method (an equal number of values in each interval). He preferred the former, as being less artificial, though he proposed to exclude extreme values from the calculation.
Others, like Block and Vauthier, did not choose between the two approaches. According to Block, the choice depended on the "look" of the data series. Nature indicated the interval limits in some cases ; at other times that indication was missing and a mathematical method had to be used. Vauthier underlined the defects of both approaches and did not come down in favour of either.
A method similar to von Mayr´s was among the propositions made in 1901 by Cheysson and Bertillon. Yet Cheysson was the leading French advocate of Ficker´s "natural method" : in an article of 1887, he demonstrated that the "artificial method" of von Mayr, when applied to French departmental densities, produced a very unsatisfactory result : all the departments would be in the first group, except the Seine which would be in the seventh, leaving all the intermediate groups empty. "My view is that the grouping mode should be adjusted to every statistical phenomena. What is needed here are made-to-measure clothes, not a ready-made garment, which, under the pretext that it fits everyone, fits no one."
Nowadays, there are over a hundred methods for dividing a series in class intervals16. But modern cartography has definitely opted for the "made-to-measure" approach. Every data set is considered and processed individually, according to its distribution features. In the nineteenth century, the different methods were considered to be competing, not complementary. This partly explains the failure of the statisticians. But another important question was that concerning the shading of maps.
In choropleth mapping the question is not purely mathematical ; it is also graphic. Three processes were employed in the nineteenth century : gradual shadings of a single tone, gradual shadings of two tones, and different colours, graded or not17.
The graphic production of the period is mainly monochromatic. So from the point of view of standardization, a monochromatic system appeared to be a simple and obvious choice, as well as a cheaper one. Ficker and Mayr agreed on this point at The Hague. The process had a semiotic logic, "since it is a matter of one order of facts, which changes from place to place, not in nature, but in intensity"18. However, there was not the same agreement about the number of shades or levels of intensity. Ficker and Mayr proposed ten shades, but some statisticians, like Maurice Block, thought that was too many. According to Block, five would be enough, with six or seven in special cases.
In practice, this number was impossible to fix, because there was too great a diversity of use. Moreover, faults were identified in the monochromatic system : for example, it concealed the arithmetic mean. Thus in the last decades of the century, several statisticians adopted a two-colour method. Emile Levasseur recommended blue, in increasing shades from the minimum value up to the arithmetic mean, then red for the values above the arithmetic mean. Cheysson preferred to represent in white the values near the mean. Bertillon advocated decreasing shades from the mean, to avoid too sharp a contrast.
Gradual shadings of two tones were not a real progress, since we know today that readers will confuse them. At the time, however, it was not criticized on visual grounds : many statisticians were surprised that two colours could be applied to a single phenomenon. Although the two-colour method was not widely supported, it was a further obstacle to standardization.
Finally, a few authors, like Toussaint Loua in France, represented the series using different colours. But while different colours were suited to qualitative informations they were unsuited to quantitative data. The reader cannot spontaneously reconstruct a visual order between the categories. Most statisticians were well aware of this defect, and rejected this last method. This was one of the main semiotical rules produced by statisticians. Bertillon and Cheysson included it in their text of 1901.
We can try to point out the possible explanations for the failure of the project of standardization. Two concepts of graphical statistics can be identified. One, the artistic concept, is liberal and traditional. According to this, maps and diagrams are a matter of creation and imagination, for which strict rules are unnecessary. The other concept is rigorous and progressist, and it relies on a communicational approach. Signs form a language, and a language needs conventions. The first conception prevailed because no agreement could be reached about precise rules. There were too many different uses. In any case, an agreement was not an urgent imperative. The statisticians´ debates concerned mainly descriptive statistics, while international comparisons were a question of secondary importance.
Statisticians did not achieve their comprehensive grammar, merely a few rules. They agreed, for example, upon the parallel progression of values and shades (i.e. darker shades for higher values), and the mistaken use of different colours. But they made two confusions. The first was between optional and compulsory elements of the code. Optional elements, such as the geometrical shape of proportional symbols, were not subject to standardization. The proportionality was all that had to be established. The second confusion was between two types of rules : of construction and of legibility. Thus flow line maps were sometimes excluded because of the confusion produced in some places where traffic was dense.
Finally, statisticians considered the methods in terms of competition rather than complementarity. The syntax was impossible, if one rule had to be chosen to the exclusion of the others.
