


%\chapter*{Part II Introduction}{Introduction de la Partie II}
\chapter*{Introduction de la Partie II}


% to have header for non-numbered introduction
%\markboth{Introduction}{Introduction}


%\headercit{}{}{}


%---------------------------------------------------------------------------



\bigskip


% metaphore de metaphore de ... merde marche pas, et pas de fil directeur.
%. -> trouver fil directeur avec autres intros ? // conclusions ? // personnages ?


\textit{Il aura finalement pu le faire, ce voyage. Pas, ou très peu de villes. Quelle âme dans ces \emph{street} et \emph{avenues} perpendiculaires, qu'on traverse nécessairement en bagnole. Encore un plein, à croire que c'est fait exprès, pour le charme de l'odeur d'essence. Tiens ça serait amusant de regarder ce que racontent ces stations d'ailleurs, à garder en tête. Un aller-retour au pas de course au Mont Elbert, puis à Longs Peak. On sort bientôt du Colorado, faudra dire au revoir au gummy bears. Damn it, Denver est si proche, ça vaudrait la peine. Tant pis, the mountains are calling and I must go, comme dirait l'autre. Que connait-on finalement d'un territoire en conséquence de nos découvertes si sélectives ? Une infime partie du spectre des échelles ? Une infime étendue spatiale : on ne s'invente pas une dimension supplémentaire si facilement. Peut être au moins la prise de conscience des antagonismes, des dualités. Et la conscience d'avoir à chaque fois dû privilégier l'un des aspects. Pour faire des ponts il faut être préparé. Pour voir le monde par un regard qui en capture plusieurs, il faut déjà avoir \emph{compris}, c'est à dire intégré subjectivement, les processus correspondants. Souvenir d'une des premières courses sérieuses : les arêtes de la Meije, 23h consécutives pour terminer par des hallucinations sur le chemin à prendre que les étincelles des crampons sur les éboulis ne suffisaient plus à éclairer dans la nuit qui était retombée. \emph{A fine line}, ce ressenti concret du gouffre de part et d'autre qui implique le tâtonnement, s'ancre dans l'inconscient avant même d'avoir atteint le stade des hallucinations : nous parcourons à chaque instant une fine arête, qui est autant celle de l'arbitraire du road trip que celle des ponts qui résistent difficilement quand vient la crue. Sur cette arête, les points d'ancrage bien évidemment solides mais aussi hétérogènes sont gages de vie : la diversité combat l'adversité.}

% suite des histoires : c'est quoi ma vie finalement ? quels souvenirs chers ? quelle identite ? psych necessaire ! catas - co ... ; a quelle periode, pourquoi, comment.


\bigskip

%\stars


Un paradoxe intrinsèque à nombre de démarches de production de connaissance est un besoin de consistence intrinsèque et d'une portée satisfaisante d'explication des phénomènes concernés, qui s'oppose à une inévitable réduction des dimensions explorées mais également à la fragilité des ponts qu'elle tente de former vers d'autres corpus de connaissances. L'image prise ci-dessus suggère que le tâtonnement, c'est à dire une progression pas à pas sans précipitations, ainsi que la solidité des ancrages, sont des atouts solides pour affronter ce paradoxe.

% POURQUOI ces thématiques : rajouter un paragraphe !

Cette partie ouvre directement les pistes de réponse thématiques pour la modélisation de la co-évolution que nous avons évoqué en conclusion de la première partie, et pose ainsi ces ancrages forts. Elle pose toutefois des bases sans entrer dans le coeur du sujet par ce souci de robustesse par entrée progressive, et construit donc les \emph{briques élémentaires} de notre démarche. Deux chapitres traitent ainsi successivement les thématiques suivantes :
\begin{enumerate}
	\item Un premier chapitre s'intéresse à la Théorie Evolutive Urbaine est une entrée privilégiée sur les systèmes urbains d'un point de vue évolutif, et intègre en son coeur un point de vue multi-scalaire de ces systèmes. Il éclaire des propriétés fondamentale des systèmes territoriaux impliquées par la théorie évolutive, en introduisant une première analyse empirique de la variabilité spatiale des interactions entre forme urbaine et forme de réseau, puis en développant une méthodologie de caractérisation statistique de la co-évolution (au sens intermédiaire de la population). Il introduit ensuite un premier modèle d'interaction entre système de ville et flux du réseau de transport, avec réseau statique.
	\item Un second chapitre explore le concept de morphogenèse, qui permet une entrée conceptuelle à la caractéristique de modularité nécessaire pour avoir co-évolution. Après avoir développé une définition interdisciplinaire de la morphogenèse, il introduit un modèle de morphogenèse urbaine basé sur des processus d'agrégation-diffusion pour la densité de population, et est ensuite couplé séquentiellement à un modèle de génération de réseau.
\end{enumerate}







\stars





%---------------------------------------------------------------------------


\chapter*{Préliminaires mathématiques}


Afin de toucher l'audience la plus large possible, nous proposons de preciser dans cet intermède préliminaire les definitions de notions ou méthodes clés qui seront utilisées de manière par la suite, souvent hors d'un cadre mathématique. Ce choix permet de garder un cadre rigoureux sans rendre indigeste la lecture du manuscrit à une grande partie de son public légitime.


Sauf indication, les specifications données ici feront référence lors de l'utilisation des termes correspondants.



\subsection*{Stochastic Processes}{Processus stochastiques}

\paragraph{Stationarity}{Stationnarité}

Nous utiliserons une notion faible de la stationnarité des processus stochastiques, puisqu'on la mobilisera pour des analyses empiriques sur lesquelles la taille des données ne permettra pas des tests sur les distributions completes. Soit $X_i$ un processus stochastique


\paragraph{Ergodicity}{Ergodicité}

La notion d'ergodicité sera utilisée dans le cadre de l'universalité des processus spatio-temporels. Soit $X(t,\vec{x})$ un processus stochastique spatio-temporel



\subsection*{Dynamical systems}{Systèmes dynamiques}

\paragraph{Chaos}{Chaos}


Un système dynamique $\dot{X}=\Phi(X,t)$ sera dit chaotique si ses exposants de Liapounov sont strictement positifs dans une region non-négligeable de l'espace des conditions initiales. Pour rappel, le flot de Poincarré est défini de manière univoque par $X_0 \mapsto \Phi(X_0,t_0)$.


\subsection*{Agent-based modeling}{Modélisation basée-agents}





\subsection*{Statistics}{Statistiques}


\paragraph{Correlation}{Correlation}

Sauf indication contraire, nous estimerons la covariance entre deux processus par estimateur de Pearson non-biaisé, c'est à dire si $(X_i,Y_i)_i$ est un jeu d'observations des processus $X,Y$, la correlation est estimée par

\[
\hat{\rho} = \frac{\hat{\Covb{X}{Y}}}{\sqrt{\hat{\sigma} \left[X\right] \cdot \hat{\sigma}\left[Y\right]}}
\]




\paragraph{Granger causality}{Causalité de Granger}


Une série temporelle multi-dimensionnelle $X(t)$ présente une causalité de Granger si avec $X(t) = A\cdot \left(X(t-\tau)\right)_{\tau >0} + \varepsilon$, il existe $\tau,i$ tels que $a_{i\tau}>0$ significativement. Nous utiliserons une version faible de la causalité de Granger, c'est à dire un test sur les correlations retardées, pour quantifier des relations entre variables aléatoires définies dans l'espace et dans le temps.




\paragraph{Geographically Weighted Regression}{Regression Géographique Pondérée}


La Régression Géographique Pondérée est une technique d'estimation de modèles statistiques permettant de prendre en compte la non-stationnarité spatiale des processus. Si $Y_i$ est une variable à expliquer et $X_i$ un jeu de variables explicatives, mesurés en des mêmes points de l'espace, on estime un modèle $Y_i = f(X_i,\vec{x}_i)$ à chaque point $\vec{x}_i$, en prenant en compte les observations par pondération spatiale autour du point, où les poids sont fixés par un noyau pouvant prendre plusieurs formes (par exemple noyau exponentiel $w_i(\vec{x}) = \exp\left(- \norm{\vec{x} - \vec{x_i}} / d_0\right)$).




\paragraph{Machine learning}{Apprentissage statistique}


On désignera par \emph{Apprentissage supervisé} toute méthode d'estimation d'une relation entre variables $Y=f(X)$ où la valeur de $Y$ est connue sur un échantillon de données. On parlera de classification si la variable est discrete. La classification non-supervisée consiste à construire $Y$ lorsque seul $X$ est donné. On utilisera pour classifier une technique basique qui donne de bons résultats sur des données qui n'ont pas une structure exotique : la méthode des \emph{k-means}, répétée un nombre suffisant de fois pour prendre en compte son caractère stochastique. Le complexité du \emph{k-means} est polynomiale en moyenne, bien que la résolution exacte du problème de partition soit NP-difficile.




\paragraph{Overfitting}{Overfitting}

% AIC

La question de l'overfitting est particulièrement importante lors de l'estimation de modèles, puisque un nombre trop important de paramètres pourra conduire a capturer le bruit de realisation comme structure. Lors de l'estimation de modèles statistiques, des critères d'information sont mobilisables pour quantifier le gain d'information produit par l'ajout d'un paramètre, et obtenir un compromis entre performance et parcimonie.


Le \emph{Critère d'Information d'Akaike} (AIC) permet de quantifier le gain d'information permis par l'ajout de paramètres dans un modèle. Pour un modèle statistique qui dispose d'une Fonction de Vraisemblance (\emph{Likelihood}), l'AIC est alors défini par $AIC = 2k - 2 \ln{\mathcal{L}}$ si $k$ est le nombre de paramètres du modèle et $\mathcal{L}$ la valeur maximale de la fonction de vraisemblance. \cite{akaike1998information} montre que cette expression correspond à une estimation du gain d'information de Kullback-Leiber. Une correction pour les petits échantillons de taille $n$ est donnée par $AICc = 2 (k + \frac{k^2 + k}{n-k -1} - 2 \ln{\mathcal{L}})$.

Un critère similaire mais dérivé dans un cadre bayésien est le \emph{Critère d'Information Bayésien} (BIC)~\cite{burnham2003model}, qui conduit à une pénalisation plus forte du nombre de paramètres : $BIC = \ln n \cdot k - 2 \ln{\mathcal{L}}$.


Ces critères sont appliqués pour la sélection de modèles en étudiant leur différences entre modèles (seules les différences ont un sens, ceux-ci étant définis à une constante près) : le ``meilleur'' modèle est celui ayant le critère le plus faible. Dans le cas de modèles de performance comparables, il peut être pertinent de combiner les modèles par les poids d'Akaike $w_i = \exp (- \Delta AIC / 2)$.




\subsection*{Model Exploration}{Exploration de modèles}


%\paragraph{Discrepancy}{Discrépance}



\paragraph{Experience plan by Sampling}{Plan d'expérience par échantillonnage}

Le sort de la dimension (\emph{Dimensionality Curse}), qui correspond simplement au fait que la taille de l'espace des paramètres est exponentielle en le nombre de paramètre. Lorsque celle-ci grandit mais qu'on veut garder un aperçu du comportement d'un modèle sur des valeurs très variées des paramètres d'entrée, on peut alors échantillonner l'espace par un nombre donné de point.


L'échantillonnage par Hypercube Latin (LHS) permet d'assurer que pour chaque dimension, l'ensemble de la plage des valeurs est couverte.


% mais pas efficient si modele tres irregulier : evoquer algos genetiques, PSE.

 

\paragraph{Genetic algorithm calibration}{Calibration par algorithme génétique}

% algo gen standard pour calibration.

Nous utilisons l'algorithme standard implémenté dans OpenMole, décrit en détails par~\cite{pumain2017evaluation}. Il s'agit d'une extension stochastique de l'algorithme NSGA2 pour l'optimisation multi-objectif.













