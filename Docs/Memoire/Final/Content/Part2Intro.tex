


%\chapter*{Part II Introduction}{Introduction de la Partie II}
\chapter*{Introduction de la Partie II}


% to have header for non-numbered introduction
%\markboth{Introduction}{Introduction}


%\headercit{}{}{}


%---------------------------------------------------------------------------



\bigskip

%\textit{Il aura finalement pu le faire, ce voyage. Pas, ou très peu de ville. Quelle âme dans ces \emph{street} et \emph{avenues} perpendiculaires, qu'on traverse nécessairement en bagnole. Encore un plein, à croire que c'est fait exprès, pour le charme de l'odeur d'essence. Tiens ça serait amusant de regarder ce que racontent ces stations d'ailleurs, à garder en tête. Un aller-retour au pas de course au Mont Elbert, puis à Longs Peak. On sort bientôt du Colorado, faudra dire au revoir au gummy bears. Damn it, Denver est si proche, ça vaudrait la peine. Tant pis, the mountains are calling and I must go, comme dirait l'autre.}

%\textit{Que connait-on finalement d'un territoire en conséquence de nos découvertes si sélectives ? Une infime partie du spectre des échelles ? Une infime étendue spatiale : on ne s'invente pas une dimension supplémentaire si facilement. Peut être au moins la prise de conscience des antagonismes, des dualités. Et la conscience d'avoir à chaque fois dû privilégier l'un des aspects. Pour faire des ponts il faut être préparé. Pour voir le monde par en regard qui en capture plusieurs, il faut l'avoir déjà vu avec chacun, et avec chacun qui nous le permet.}

% metaphore de metaphore de ... merde marche pas, et pas de fil directeur.
%. -> trouver fil directeur avec autres intros ? // conclusions ? // personnages ?

%\textit{Je me souviens d'une des premières courses sérieuses, la traversée des arêtes de la Meije} -> hallucination sur chemin a prendre - 23h marche : image du travail ici ?

















%---------------------------------------------------------------------------


\chapter*{Préliminaires mathématiques}


Afin de toucher l'audience la plus large possible, nous proposons de preciser dans cet intermède préliminaire les definitions de notions ou méthodes clés qui seront utilisées de manière répétée par la suite. Sauf indication, les specifications données ici feront reference lors de l'utilisation des termes correspondants.



\subsection*{Stochastic Processes}{Processus stochastiques}

\paragraph{Stationarity}{Stationnarité}

Nous utiliserons une notion faible de la stationnarité des processus stochastiques, puisqu'on la mobilisera pour des analyses empiriques sur lesquelles la taille des données ne permettra pas des tests sur les distributions completes. Soit $X_i$ un processus stochastique


\paragraph{Ergodicity}{Ergodicité}

La notion d'ergodicité sera utilisée dans le cadre de l'universalité des processus spatio-temporels. Soit $X(t,\vec{x})$ un processus stochastique spatio-temporel



\subsection*{Dynamical systems}{Systèmes dynamiques}

\paragraph{Chaos}{Chaos}


Un système dynamique $\dot{X}=\Phi(X,t)$ sera dit chaotique si ses exposants de Liapounov sont strictement positifs dans une region non-négligeable de l'espace des conditions initiales. Pour rappel, le flot de Poincarré est défini de manière univoque par $X_0 \mapsto \Phi(X_0,t_0)$.


\subsection*{Agent-based modeling}{Modélisation basée-agents}





\subsection*{Statistics}{Statistiques}


\paragraph{Correlation}{Correlation}

Sauf indication contraire, nous estimerons la covariance entre deux processus par estimateur de Pearson non-biaisé, c'est à dire si $(X_i,Y_i)_i$ est un jeu d'observations des processus $X,Y$, la correlation est estimée par

\[
\hat{\rho} = \frac{\hat{\Covb{X}{Y}}}{\sqrt{\hat{\sigma} \left[X\right] \cdot \hat{\sigma}\left[Y\right]}}
\]




\paragraph{Granger causality}{Causalité de Granger}


Une série temporelle multi-dimensionnelle $X(t)$ présente une causalité de Granger si avec $X(t) = A\cdot \left(X(t-\tau)\right)_{\tau >0} + \varepsilon$, il existe $\tau,i$ tels que $a_{i\tau}>0$ significativement. Nous utiliserons une version faible de la causalité de Granger, c'est à dire un test sur les correlations retardées, pour quantifier des relations entre variables aléatoires définies dans l'espace et dans le temps.




\paragraph{Geographically Weighted Regression}{Regression Géographique Pondérée}


La Régression Géographique Pondérée est une technique d'estimation de modèles statistiques permettant de prendre en compte la non-stationnarité spatiale des processus. Si $Y_i$ est une variable à expliquer et $X_i$ un jeu de variables explicatives, mesurés en des mêmes points de l'espace, on estime un modèle $Y_i = f(X_i,\vec{x}_i)$ à chaque point $\vec{x}_i$, en prenant en compte les observations par pondération spatiale autour du point, où les poids sont fixés par un noyau pouvant prendre plusieurs formes (par exemple noyau exponentiel $w_i(\vec{x}) = \exp\left(- \norm{\vec{x} - \vec{x_i}} / d_0\right)$).




\paragraph{Machine learning}{Apprentissage statistique}


On désignera par \emph{Apprentissage supervisé} toute méthode d'estimation d'une relation entre variables $Y=f(X)$ où la valeur de $Y$ est connue sur un échantillon de données. On parlera de classification si la variable est discrete. La classification non-supervisée consiste à construire $Y$ lorsque seul $X$ est donné. On utilisera pour classifier une technique basique qui donne de bons résultats sur des données qui n'ont pas une structure exotique : la méthode des \emph{k-means}, répétée un nombre suffisant de fois pour prendre en compte son caractère stochastique. Le complexité du \emph{k-means} est polynomiale en moyenne, bien que la résolution exacte du problème de partition soit NP-difficile.




\paragraph{Overfitting}{Overfitting}

% AIC

La question de l'overfitting est particulièrement importante lors de l'estimation de modèles, puisque un nombre trop important de paramètres pourra conduire a capturer le bruit de realisation comme structure. Lors de l'estimation de modèles statistiques, des critères d'information sont mobilisables pour quantifier le gain d'information produit par l'ajout d'un paramètre, et obtenir un compromis entre performance et parcimonie.


Le \emph{Critère d'Information d'Akaike} (AIC) permet de quantifier le gain d'information permit par l'ajout de paramètres dans un modèle. Pour un modèle statistique qui dispose d'une Fonction de Vraisemblance (\emph{Likelihood})




\subsection*{Model Exploration}{Exploration de modèles}


%\paragraph{Discrepancy}{Discrépance}



\paragraph{LHS Sampling}{Echantillonnage LHS}

Le sort de la dimension (\emph{Dimensionality Curse}), qui correspond simplement au fait que la taille de l'espace des paramètres est exponentielle en le nombre de paramètre. Lorsque celle-ci grandit mais qu'on veut garder un aperçu du comportement d'un modèle sur des valeurs très variées des paramètres d'entrée, on peut alors échantillonner l'espace par un nombre donné de point.


% mais pas efficient si modele tres irregulier : evoquer algos genetiques, PSE.

 

\paragraph{NSGA}{NSGA}

% algo gen standard pour calibration.














